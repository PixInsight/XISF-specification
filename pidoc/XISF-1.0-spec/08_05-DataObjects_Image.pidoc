
\subsection { \label xisf_image XISF Image } {

   \subsection { \label image_structure Structure and Properties } {

      In the context of this specification, an image is an object with the following structure and properties:

      \list[spaced] {

         { An image is a set of scalars or complex numbers structured as a non-empty, finite ordered collection of \im{n}-dimensional arrays.\ref nist_array }

         { The \e dimensionality of the image is \im{n > 0}. }

         { Each \im{n}-dimensional array is known as a \e channel or \e (hyper)plane of the image. }

         { All image channels have identical lengths in each one of their \im n dimensions. }

         { Let \im{m > 0} be the number of channels in the image. Any channel \e must be addressable by its \e {channel index} \im{c}, an integer such that \im{#: 0 \le c < m :#}. }

         { Let \im d_j be the length of any channel in the \im{j}-th dimension, \im{#: 0 \le j < n :#}. }

         { An image with any length \im{#: d_j = 0 :#} for \im{#: 0 \le j < n :#} is an \e {empty image}. Empty images cannot be serialized in an XISF unit. }

         { A \e {pixel coordinate} is an integer array index \im i_j such that \im{#: 0 \le i_j < d_j :#}. }

         { An \e {image coordinate} is any real number \im t_j such that \im{#: \lfloor t_j \rfloor = i_j \enspace \hbox{for} \enspace 0 \le t_j < d_j :#}. }

         { Any \im{m}-tuple formed with the set of scalars or complex numbers at the same pixel coordinates \im{#: i_0,\dots,i_{n-1} :#} is a \e pixel. }

         { The \im m components of a pixel are \e {pixel samples}. }

         { Any pixel \e must be addressable by its \im{n}-tuple \im{#: \{i_0,\dots,i_{n-1}\} :#} of pixel coordinates. }

         { Any pixel sample \e must be addressable by the \im{(n+1)}-tuple \im{#: \{c,i_0,\dots,i_{n-1}\} :#} of channel index and pixel coordinates. }

         { The total number of pixels in an image is \im{#: N = \prod_{j=0}^{n-1} d_j :#}. }

         { The total number of pixel samples in an image is \im{#: M = N \times m :#}. }

         { For images with a visual representation role, pixel samples \e must be representable in a \e {color model}.\ref gonzalez_2008_color_model \ref wikipedia_color_model }

         { The color model where pixel samples are represented, if defined, \e should be augmented with a number of viewing conditions and colorimetric properties, which define the \e {color space}\ref cie_colorimetry of the image. }

         { The first \im{#: r \le m :#} channels strictly required to define the color model (or color space) of an image, with indexes \im{#: 0,\dots,r-1 :#}, are \e {nominal channels}. }

         { Excess channels beyond nominal channels, with indexes \im{#: r,r+1,\dots,m-1 :#}, are collectively known as \e {alpha channels}. }

         { The roles of alpha channels are implementation-defined; however, for images with a visual representation role the first alpha channel, at index \im{r}, \e should define the transparency of the image for alpha-compositing operations.\ref porter_1984 }

         { Every real or integer image defines a visually representable numerical range, which we formalize as a \lref representable_range {representable range} property. }
      }

      The mathematical symbols and terminology introduced in the above list will be used, unless otherwise noted, in the rest of this section.

      \vs[length:2em]

      \figure {

         \figtag \s { Structure of a two-dimensional image. }

         \vs[length:2em]

         \center \image[width:62.95em] { 2d-image.svg }
      }
   }

   \subsection { Geometrical Conventions } {

      In a two-dimensional image we have \im n=2 and the lengths \im d_0 and \im d_1 are known as the \e width and \e height of the image, respectively. Conventionally, the dimensions \im i_0 and \im i_1 are known as the \e X-axis and \e Y-axis, respectively. It is customary to use the symbols \im x and \im y to represent coordinates in the first and second dimensions, respectively. We also say that \im i_0 is the \e {horizontal axis} and \im i_1 is the \e {vertical axis}. The point with pixel coordinates \im{#: x = y = 0 :#} is said to be the \e {top-left corner} or the \e origin of the image. Note that all of these words don't necessarily imply any particular orientation of the \e represented image; they are just conventional designations.

      In a three-dimensional image, \im n=3 and the dimensions \im{d_0}, \im d_1 and \im d_2 are the \e width, \e height and \e depth of the image, respectively. The dimensions \im{i_0}, \im i_1 and \im i_2 are known conventionally as the \e X-axis, \e Y-axis and \e Z-axis, respectively. It is customary to use the symbols \im{x}, \im y and \im z to represent coordinates in the first, second and third dimensions, respectively. \im i_0 is the \e {horizontal axis}, \im i_1 is the \e {vertical axis} and \im i_2 is the \e {depth axis}. The point with pixel coordinates \im{#: x = y = z = 0 :#} is said to be the \e origin of the image. Again, these designations are purely conventional and don't imply any particular representation of the image.

      For one-dimensional images and images with dimensionalities higher than three, such as tesseracts and other hypercubes, there are no conventional names for axes and lengths. Normally these structures are manipulated as mathematical objects in purely abstract terms without a perceptual meaning or a visual role.
   }

   \subsection { \label pixel_storage_models Pixel Storage Models } {

      Two pixel storage models are formalized by this specification: \e planar and \e normal. The planar storage model is appropriate for applications that store and organize images by separate channels in memory. The normal storage model is best suited for applications that organize images by pixels, that is, applications that store the components of each pixel at consecutive memory locations.

      Irrespective of the pixel storage model, the total space in bytes required to store an uncompressed image channel equals \im{#: N \times b :#}, where \im b is the size in bytes of a pixel sample. Similarly, the total space in bytes required to store an uncompressed image is \im{#: M \times b :#}.

      \subsection { \label planar_pixel_storage_model Planar Pixel Storage Model } {

         In this model each channel is stored in a separate block:

         \list[spaced] {

            { In the planar storage model, each channel of an image \e shall be stored as a contiguous sequence of pixel samples. }

            { For a given channel index \im{#: c \; | \; 0 \le c < m :#}, all pixel samples \e shall be stored in \e {pixel coordinate order}. The coordinates of the stored sequence of pixel samples can be represented as:\n\n

               \equation { #:
                  $$
                  \begin{array}{l l l}
                     \{\, c, i_j = 0          && \; | \; 0 \le j < n \,\} \\
                     \{\, c, i_0 = 1, i_j = 0 && \; | \; 1 \le j < n \,\} \\
                     \{\, c, i_0 = 2, i_j = 0 && \; | \; 1 \le j < n \,\} \\
                                          & \vdots &                      \\
                     \{\, c, i_j = d_j-1      && \; | \; 0 \le j < n \,\} \\
                  \end{array}
                  $$
               :# }
            }
         }

         \vs[length:2em]

         \figure[numbered:fig_planar_pixel_storage_model] {

            \figtag \s { A two-dimensional image in the planar pixel storage model. } Each square represents a pixel sample with its coordinates \im{#: \{c,i_0,i_1\} :#} written vertically, where \im c is a channel index and \im i_0 and \im i_1 are pixel coordinates. All pixel samples are stored as a single contiguous block from top to bottom and left to right (arrows indicate storage order).

            \vs[length:2em]

            \center \image[width:41.46em] { planar-pixel-storage-model.svg }
         }
      }

      \subsection { Normal Pixel Storage Model } {

         In this model all pixel samples are stored in a single block:

         \list[spaced] {

            { In the normal storage model, all pixel samples of an image \e shall be stored as a contiguous sequence. }

            { All pixels \e shall be stored in \e {pixel coordinate order}. The coordinates of the stored sequence of pixel samples can be represented as:\n\n

               \equation { #:
                  $$
                  \begin{array}{l l l l}
                     \{\, c = 0,   & i_j = 0          && \; | \; 0 \le j < n \,\} \\
                     \{\, c = 1,   & i_j = 0          && \; | \; 0 \le j < n \,\} \\
                                            && \vdots &                            \\
                     \{\, c = m-1, & i_j = 0          && \; | \; 0 \le j < n \,\} \\
                     \{\, c = 0,   & i_0 = 1, i_j = 0 && \; | \; 1 \le j < n \,\} \\
                     \{\, c = 1,   & i_0 = 1, i_j = 0 && \; | \; 1 \le j < n \,\} \\
                                            && \vdots &                            \\
                     \{\, c = m-1, & i_0 = 1, i_j = 0 && \; | \; 1 \le j < n \,\} \\
                                            && \vdots &                            \\
                     \{\, c = 0,   & i_j = d_j-1      && \; | \; 0 \le j < n \,\} \\
                     \{\, c = 1,   & i_j = d_j-1      && \; | \; 0 \le j < n \,\} \\
                                            && \vdots &                            \\
                     \{\, c = m-1, & i_j = d_j-1      && \; | \; 0 \le j < n \,\} \\
                  \end{array}
                  $$
               :# }
            }
         }

         \vs[length:2em]

         \figure {

            \figtag \s { A two-dimensional image in the normal pixel storage model. } As in Figure \figref fig_planar_pixel_storage_model, each square represents a pixel sample with its coordinates written vertically. Colors have been used to indicate image channels. As you can see by comparing both figures, in the normal model pixel samples are grouped by coordinates (by rows and columns in the case of a 2-D image) instead of by channels.

            \vs[length:2em]

            \center \image[width:34.03em] { normal-pixel-storage-model.svg }
         }
      }
   }

   \subsection { \label image_color_spaces Color Spaces } {

      The following color spaces are formally supported by this specification for storage of pixel data in XISF units: Grayscale (monochrome), RGB, and CIE L*a*b*.\ref cie_lab

      An in-depth description of color spaces is beyond the scope of this specification. The reader should refer to the literature for further information on this subject; for example, see references \ref cie_colorimetry, \ref gonzalez_2008_color_model, \ref tkalcic_2003 and \ref www_bruce_lindbloom.

      To remove any possible ambiguity in the specification of CIE L*a*b*, we'll describe the necessary color space transformation algorithms in the next subsections.

      \subsection { \label rgb_working_space RGB Working Space } {

         All color space transformations \e shall be performed relative to a colorimetrically defined RGB working space (RGBWS) associated with the image. An RGB working space is a set \im{#: \{ \mathbf{W}, \gamma, \mathbf{x}, \mathbf{y}, \mathbf{Y} \} :#}, where:

         \list[spaced] {

            { \im{#: \mathbf{W} = (x_W,y_W,Y_W) :#} is a reference white. In this specification, all RGB working space parameters \e shall be relative to the standard D50 reference white.\ref iso_3664 }

            { \im{#: \gamma :#} is an exponent for linearization of RGB components. }

            { \im{#: \mathbf{x} = (x_R,x_G,x_B) :#} and \im{#: \mathbf{y} = (y_R,y_G,y_B) :#} are the chromaticity coordinates of the RGB primaries. }

            { \im{#: \mathbf{Y} = (Y_R,Y_G,Y_B) :#} are the luminance coefficients of the RGB primaries. }
         }

         All chromaticity coordinates and luminance coefficients \e shall be normalized to the \[0,1\] range.

         For spaces not originally defined with respect to the D50 reference white, a chromatic adaptation algorithm \e must be applied to convert coordinates and coefficients to D50. The Bradford chromatic adaptation transform\ref icc_bradford is \e recommended.

         When no RGB working space is specified for a given image, the default RGBWS associated with the image \e shall be the sRGB space.\ref iec_srgb The chromaticity coordinates and luminance coefficients of sRGB relative to D50 (after chromatic adaptation from the D65 reference white with the Bradford algorithm) are the following:

         \equation[unnumbered] { #:
            $$
            \hbox{sRGB}_{\mathrm{D50}} : \left\{ \begin{array}{l c l}
               x_R &=& 0.648431 \\
               x_G &=& 0.321152 \\
               x_B &=& 0.155886 \\
               y_R &=& 0.330856 \\
               y_G &=& 0.597871 \\
               y_B &=& 0.066044 \\
               Y_R &=& 0.222491 \\
               Y_G &=& 0.716888 \\
               Y_B &=& 0.060621 \\
            \end{array}
            \right. \, .
            $$
         :# }

         The sRGB space uses a special linearization function instead of a gamma exponent, as described below.

         The RGBWS associated with a color image, either explicitly or by default, \e shall be used for all required color space transformations when the image is serialized encoded in a color space different from RGB. For example, if a color image is being stored encoded in the CIE L*a*b* space, an encoder \e must convert its pixel sample values from RGB to CIE L*a*b* using its associated RGBWS and the corresponding color space conversion algorithm, as described below. Conversely, if an image has been stored encoded in CIE L*a*b*, a decoder \e must use its associated RGBWS and the appropriate algorithm to convert pixel samples from CIE L*a*b* to RGB.
      }

      \subsection { RGB to CIE XYZ Conversion } {

         Let R, G, B be the nominal components of a pixel in the RGB color space. The nominal components R', G', B' in the linear RGB space are

         \equation { #:
            $$
            \begin{array}{l c l}
               R' &=& R^{\gamma} \\
               G' &=& G^{\gamma} \\
               B' &=& B^{\gamma} \\
            \end{array} \, .
            $$
         :# }

         If the RGB working space is the sRGB space,\ref iec_srgb then a special function \e must be used instead of the equations above. Define the linearization function

         \equation { #:
            $$
            \hbox{S}(x) = \left\{ \begin{array}{l l}
               \displaystyle{\frac{x}{12.92}}                            & \hbox{if} \enspace x \le 0.04045 \\
               \\
               \left(\displaystyle{\frac{x + 0.055}{1.055}}\right)^{2.4} & \hbox{otherwise}                 \\
            \end{array}
            \right. \, .
            $$
         :# }

         Now we have, for the sRGB space:

         \equation { #:
            $$
            \begin{array}{l c l}
               R' &=& \hbox{S}(R_{\mathrm{sRGB}}) \\
               G' &=& \hbox{S}(G_{\mathrm{sRGB}}) \\
               B' &=& \hbox{S}(B_{\mathrm{sRGB}}) \\
            \end{array} \, .
            $$
         :# }

         The CIE XYZ components are given by

         \equation { #:
            $$
            \left( \begin{array}{l l}
               X \\
               Y \\
               Z \\
            \end{array} \right) = \hbox{M} \left( \begin{array}{l l}
               R' \\
               G' \\
               B' \\
            \end{array} \right) \, ,
            $$
         :# }

         with the transformation matrix

         \equation { #:
            $$
            \hbox{M} = \left( \begin{array}{c c c}
               Y_R \cdot x_R / y_R & Y_G \cdot x_G / y_G & Y_B \cdot x_B / y_B \\
               Y_R & Y_G & Y_B \\
               Y_R (1 - x_R - y_R)/y_R & Y_G (1 - x_G - y_G)/y_G & Y_B (1 - x_B - y_B)/y_B \\
            \end{array} \right) \, .
            $$
         :# }
      }

      \subsection { CIE XYZ To RGB Conversion } {

         Let X, Y, Z be the nominal components of a pixel in the CIE XYZ color space. The components R', G', B' in the linear RGB space can be found by multiplication with the inverse transformation matrix:

         \equation { #:
            $$
            \left( \begin{array}{l l}
               R' \\
               G' \\
               B' \\
            \end{array} \right) = \hbox{M}^{-1} \left( \begin{array}{l l}
               X \\
               Y \\
               Z \\
            \end{array} \right) \, .
            $$
         :# }

         Then the RGB components are given by

         \equation { #:
            $$
            \begin{array}{l c l}
               R &=& R'^{\,1/\gamma} \\
               G &=& G'^{\,1/\gamma} \\
               B &=& B'^{\,1/\gamma} \\
            \end{array} \, .
            $$
         :# }

         If the RGB working space is the sRGB space,\ref iec_srgb then a special function \e must be used instead of the equations above. Define the delinearization function

         \equation { #:
            $$
            \hbox{T}(x) = \left\{ \begin{array}{l l}
               12.92 \times x          & \hbox{if} \enspace x \le 0.0031308 \\
               \\
               1.055 \, x^{1/2.4} - 0.055 & \hbox{otherwise}                \\
            \end{array}
            \right. \, .
            $$
         :# }

         Now we have, for the sRGB space:

         \equation { #:
            $$
            \begin{array}{l c l}
               R_{\mathrm{sRGB}} &=& \hbox{T}(R') \\
               G_{\mathrm{sRGB}} &=& \hbox{T}(G') \\
               B_{\mathrm{sRGB}} &=& \hbox{T}(B') \\
            \end{array} \, .
            $$
         :# }
      }

      \subsection { CIE XYZ to CIE L*a*b* Conversion } {

         Define the function

         \equation { #:
            $$
            \hbox{f}(x) = \left\{ \begin{array}{l l}
               x^{1/3}                                  & \hbox{if} \enspace x > \epsilon \\
               \\
               \displaystyle{\frac{\kappa x + 16}{116}} & \hbox{otherwise}                \\
            \end{array}
            \right. \, ,
            $$
         :# }

         with

         \equation[numbered:eqn_cie_epsilon_kappa] { #:
            $$
            \begin{array}{l c l}
               \epsilon &=& \displaystyle{\frac{216}{24389}} \\
               \\
               \kappa   &=& \displaystyle{\frac{24389}{27}}  \\
            \end{array} \, .
            $$
         :# }

         Then the CIE L*a*b* components are:

         \equation { #:
            $$
            \begin{array}{l c l}
               L* &=& 1.16 \times \hbox{f}(Y) - 0.16       \\
               a* &=& 5 \times (\hbox{f}(X) - \hbox{f}(Y)) \\
               b* &=& 2 \times (\hbox{f}(Y) - \hbox{f}(Z)) \\
            \end{array} \, .
            $$
         :# }
      }

      \subsection { CIE L*a*b* to CIE XYZ Conversion } {

         Define the function

         \equation { #:
            $$
            \hbox{g}(x) = \left\{ \begin{array}{l l}
               x^3                                      & \hbox{if} \enspace x^3 > \epsilon \\
               \\
               \displaystyle{\frac{116 x - 16}{\kappa}} & \hbox{otherwise}                  \\
            \end{array}
            \right. \, ,
            $$
         :# }

         with \im{ \\epsilon } and \im{ \\kappa } as defined in Equation \eqnref eqn_cie_epsilon_kappa. Then the CIE XYZ components are:

         \equation { #:
            $$
            \begin{array}{l c l}
               X &=& \hbox{g}\left( \displaystyle{\frac{a*}{5}} + y \right) \\
               Y &=& \hbox{g}\left( \displaystyle{y} \right)                \\
               Z &=& \hbox{g}\left( y - \displaystyle{\frac{b*}{2}} \right) \\
            \end{array} \, ,
            $$
         :# }

         where

         \equation { #:
            $$
            y = \frac{{L*} + 0.16}{1.16} \, .
            $$
         :# }
      }

      \subsection { RGB to Grayscale Conversion } {

         A colorimetrically defined grayscale component \e shall be computed as the L* component of the CIE L*a*b* space.
      }
   }

   \subsection { \label representable_range Representable Range } {

      The representable range is a property of every real or integer XISF image, that is, of any image whose pixel samples are floating point or integer scalars. It is the range \im{#: [r_0,r_1] :#} of pixel sample values that can be represented on display devices, as we describe below. We say that \im r_0 and \im r_1 are the \e {black point} and \e {white point} of the image, respectively.

      Consider an abstract device \im{#: \mathcal{D} :#} able to generate image representations for pixel sample values in the \im{#: [v_0,v_1] :#} range. We call this range the device's \e {input range}, and we conventionally call \im v_0 and \im v_1 \e black and \e white, respectively, in the context of image representations generated by \im{#: \mathcal{D} :#}. Pixel samples outside the representable range will generate invalid, saturated representations: Any pixel sample value \im{#: x < r_0 :#} will be represented as black, while any pixel sample value \im{#: x > r_1 :#} will be represented as white. Any pixel sample \im{#: x \in [r_0,r_1]:#} will generate a valid representation \im{#: \mathcal{D}(\mbox{R}(x)) :#} as a gray level directly proportional to the input pixel sample value. Assuming a device so defined, the representable range of the image \e shall be applied for each pixel sample \im x by means of the following algorithm:

      \equation[numbered:eqn_representable_range] { #:
         $$
         \mathcal{D}(\mbox{R}(x;r_0,r_1);v_0,v_1) = \left\{ \begin{array}{l l}
            v_0                                                               & \quad \mbox{if} \enspace x < r_0 \\
            v_1                                                               & \quad \mbox{if} \enspace x > r_1 \\
            v_0 + (v_1 - v_0) \times \displaystyle{\frac{x - r_0}{r_1 - r_0}} & \quad \mbox{otherwise}           \\
         \end{array}
         \right. \, .
         $$
      :# }

      This algorithm is a simple linear mapping of pixel sample values from the representable range of an image to a device's input range.

      For example, for an image being represented on a typical 8-bit output device, such as a computer display or a printer, we would have \im{v_0 = 0} and \im{v_1 = 255}. Another example is an image processing application working internally with normalized floating point pixel data in the \im{#: [0,1] :#} range, which would apply the above algorithm with \im{v_0 = 0} and \im{v_1 = 1} (note that in this case the algorithm can be trivially simplified).

      There is no default representable range for real images whose pixel samples are encoded as floating point scalars, so in these cases the representable range \e must be declared explicitly; see the \lref bounds_image_attribute \c bounds attribute of the \lref image_core_element \c Image core element for implementation details.

      For images whose pixel samples are encoded as unsigned integer scalars, the default representable range \e shall be \im{#: [0,2^n-1] :#}, where \im n is the number of bits per pixel sample.

      For complex images, i.e. for images whose pixel samples are complex numbers, the representable range property is \e undefined. The reason for this limitation is that the role of a visually representable range, as we have described it above, is unclear for pixel data in the frequency domain and other applications of complex numerical data. The methods used for representation of complex-valued pixels are left as implementation-defined by this version of the XISF specification.

      For color images encoded in color spaces different from RGB, the representable range \e shall apply to pixel sample values \e {once converted} to the RGB color space.
   }

   \subsection { \label display_function Display Function } {

      A display function (DF) is a mathematical transformation applied to modify the visual representation of an XISF image. A display function has a set \im{#: \{ \mathbf{m}, \mathbf{s}, \mathbf{h}, \mathbf{l}, \mathbf{r} \} :#} of function parameters such that

      \list[spaced] {

         { \im{#: \mathbf{m} = (m_{RK},m_G,m_B,m_L) :#} is a vector of \e {midtones balance} parameters, }

         { \im{#: \mathbf{s} = (s_{RK},s_G,s_B,s_L) :#} is a vector of \e {shadows clipping point} parameters, }

         { \im{#: \mathbf{h} = (h_{RK},h_G,h_B,h_L) :#} is a vector of \e {highlights clipping point} parameters, }

         { \im{#: \mathbf{l} = (l_{RK},l_G,l_B,l_L) :#} is a vector of \e {shadows dynamic range expansion} parameters, }

         { \im{#: \mathbf{r} = (r_{RK},r_G,r_B,r_L) :#} is a vector of \e {highlights dynamic range expansion} parameters, }
      }

      with the following constraints for \im{#: i \in \{{\scriptstyle RK,G,B,L}\} :#}:

      \equation[unnumbered] { #:
         $$
         \begin{array}{c}
            0   \le m_i \le 1 \\
            0   \le s_i \le 1 \\
            0   \le h_i \le 1 \\
            s_i \le h_i       \\
            l_i \le 0         \\
            r_i \ge 1         \\
         \end{array} \, .
         $$
      :# }

      For DF vector parameter components, the \im{#: {\scriptstyle RK} :#}, \im{#: {\scriptstyle G} :#} and \im{#: {\scriptstyle B} :#} subindexes correspond to the red, green and blue nominal channels of RGB color images, respectively. For grayscale images, the \im{#: {\scriptstyle RK} :#} subindex corresponds to the unique grayscale nominal channel, and the \im{#: {\scriptstyle G} :#} and \im{#: {\scriptstyle B} :#} vector components are not applicable. Finally, the \im{#: {\scriptstyle L} :#} subindex applies to visualizations of the CIE L* component (or \e{lightness}) of color images.

      A decoder that claims support of display functions \e shall implement the following algorithm. For a pixel sample \im{#: x \in [0,1] :#}, define the \e {midtones transfer function}

      \equation[numbered:eqn_mtf] { #:
         $$
         \mbox{M}(x;m) = \left\{ \begin{array}{l l}
            0                                             & \quad \mbox{if} \enspace x = 0 \\
            1/2                                           & \quad \mbox{if} \enspace x = m \\
            1                                             & \quad \mbox{if} \enspace x = 1 \\
            \displaystyle{\frac{(m - 1)x}{(2m - 1)x - m}} & \quad \mbox{otherwise}         \\
         \end{array}
         \right. \, .
         $$
      :# }

      This is a smooth, continuous function passing through the points \im{(0,0)}, \im{(m,1/2)} and \im{(1,1)}, where \im m is a midtones balance DF parameter. A midtones balance of 0.5 defines a linear function. A midtones balance value below 0.5 increases the midtones, while a value above 0.5 darkens the midtones of the image. The above equation can be derived from the Bulirsch-Stoer algorithm \ref bulirsch_2010 for evaluation of the diagonal rational function, given the three fixed points of the midtones transfer function.

      Define the \e {clipping function}

      \equation[numbered:eqn_clipping] { #:
         $$
         \mbox{C}(x;s,h) = \left\{ \begin{array}{l l}
            0                                  & \quad \mbox{if} \enspace x < s \\
            1                                  & \quad \mbox{if} \enspace x > h \\
            \displaystyle{\frac{x - s}{h - s}} & \quad \mbox{otherwise}         \\
         \end{array}
         \right. \, ,
         $$
      :# }

      and the \e {expansion function}

      \equation[numbered:eqn_expansion] { #:
         $$
         \mbox{E}(x;l,r) = \frac{x - l}{r - l} \, .
         $$
      :# }

      Now for each pixel sample \im x_i of a given image plane or component \im{#: i \in \{{\scriptstyle RK,G,B,L}\} :#}, we define the display function as

      \equation[numbered:eqn_display_function] { #:
         $$
         \mbox{DF}(x_i;\mathbf{m},\mathbf{s},\mathbf{h},\mathbf{l},\mathbf{r}) = \mbox{E}( \mbox{M}( \mbox{C}(x_i;s_i,h_i); m_i );l_i,r_i ) \, .
         $$
      :# }

      The \e {identity display function} is defined by the following parameters \im{#: \forall \; i \in \{{\scriptstyle RK,G,B,L}\} :#}:

      \equation[numbered:eqn_identity_df] { #:
         $$
         \begin{array}{l l l}
            m_i & = & 1/2 \\
            s_i & = & 0   \\
            h_i & = & 1   \\
            l_i & = & 0   \\
            r_i & = & 1   \\
         \end{array} \, .
         $$
      :# }

      When no display function is specified for an image, the identity DF \e shall be assigned by default.

      For normalization to the \[0,1\] range, as required by Equations \eqnref eqn_mtf, \eqnref eqn_clipping and \eqnref eqn_expansion, Equation \eqnref eqn_representable_range \e shall be used with \im{#: v_0 = 0 :#} and \im{#: v_1 = 1 :#} if the original pixel data are encoded with a different representable range.

      Display functions are mostly useful for visualization of linear images, such as CCD and digital camera raw frames. Figure \figref fig_display_function shows a typical example with a deep-sky astronomical image.

      \vs[length:2em]

      \figure[numbered:fig_display_function] {

         \figtag \s { Display function example. }

         \s (a) Linear image. Integration of 15 CCD raw images of the M81/M82 region.

         \s (b) Linear image visualized with display function parameters \im[scale:0.8]{#: m_{RK} = 7.35 \times 10^{-4} :#}, \im[scale:0.8]{#: s_{RK} = 3.758 \times 10^{-3} :#}, and \im[scale:0.8]{#: h_{RK} = 1 :#}.

         \s (c) Linear image visualized with display function parameters \im[scale:0.8]{#: m_{RK} = 1.84 \times 10^{-4} :#}, \im[scale:0.8]{#: s_{RK} = 3.819 \times 10^{-3} :#}, and \im[scale:0.8]{#: h_{RK} = 1 :#}.

         In all cases dynamic range expansion parameters have the default values \im[scale:0.8]{#: l_{RK} = 0 :#} and \im[scale:0.8]{#: r_{RK} = 1 :#}. Display function parameters have been computed adaptively based on robust image statistics.

         \vs[length:2em]
         \group{ \block[float:left] \s a \image[float:right] M81-M82-linear.png }
         \vs
         \group{ \block[float:left] \s b \image[float:right] M81-M82-df-1.png }
         \vs
         \group{ \block[float:left] \s c \image[float:right] M81-M82-df-2.png }
      }
   }

   \subsection { Adaptive Display Function Algorithm } {

      In this subsection we describe an algorithm for the calculation of display functions based on robust image statistics. This algorithm, which has proven to yield excellent results for automatic visualization of most linear images, is \e recommended for all encoders claiming support for display functions.

      For simplicity, let's consider a two-dimensional image; if necessary, the algorithm can be extended trivially to higher dimensions. Assume also, for the sake of simplicity, that the representable range of the image is \im{#: [0,1] :#}. Consider an image channel with index \im{c}, and recall that image dimensions are symbolized by \im d_0 and \im d_1 respectively for the X and Y axes. The normalized median absolute deviation of an image channel \im c is given by

      \equation { #:
         $$
         \hbox{MADN}_c = 1.4826 \times \hbox{med}( |x_{c,0,0} - M_c|, \dots, |x_{c,d_0-1,d_1-1} - M_c| ) \, ,
         $$
      :# }

      where \im{#: \hbox{med}() :#} is the sample median function,\ref wilcox_2010 \im{#: x_{c,i,j} :#} represents the pixel sample at coordinates \im{#: \{c,i,j\} :#}, and \im M_c is the median of all pixel samples in channel \im{c}. The constant 1.4826 makes the median absolute deviation consistent with the standard deviation of a normal distribution.

      Define the parameters:

      \definition {

         \im B
         {
            Target mean background in the \im{#: [0,1] :#} range. This parameter controls the global illumination of the displayed image. The \e recommended default value is \im{B = 0.25}.
         }

         \im C
         {
            Clipping point in units of \im{#: \hbox{MADN}_c :#}, measured from the median \im{M_c}. This parameter controls the overall contrast of the displayed image. The \e recommended default value is \im{C = -2.8}.
         }
      }

      Note that these parameters are valid for all images and image channels. Set

      \equation { #:
         $$
         a_c = \left\{ \begin{array}{l l}
            0 & \quad \mbox{if} \enspace M_c \le 1/2 \\
            1 & \quad \mbox{if} \enspace M_c > 1/2   \\
         \end{array}
         \right. \, .
         $$
      :# }

      Compute the clipping points

      \equation { #:
         $$
         s_c = \left\{ \begin{array}{l l}
            0                                                              & \quad \mbox{if} \enspace           a_c = 1 \\
            0                                                              & \quad \mbox{if} \enspace \hbox{MADN}_c = 0 \\
            \hbox{min}( 1, \hbox{max}( 0, M_c + C \times \hbox{MADN}_c ) ) & \quad \mbox{otherwise}                     \\
         \end{array}
         \right. \, ,
         $$
      :# }

      \vs

      \equation { #:
         $$
         h_c = \left\{ \begin{array}{l l}
            1                                                              & \quad \mbox{if} \enspace           a_c = 0 \\
            1                                                              & \quad \mbox{if} \enspace \hbox{MADN}_c = 0 \\
            \hbox{min}( 1, \hbox{max}( 0, M_c - C \times \hbox{MADN}_c ) ) & \quad \mbox{otherwise}                     \\
         \end{array}
         \right. \, ,
         $$
      :# }

      and the midtones balance

      \equation { #:
         $$
         m_c = \left\{ \begin{array}{l l}
            \mbox{M}(M_c - s_c;B) & \quad \mbox{if} \enspace a_c = 0 \\
            \mbox{M}(B;h_c - M_c) & \quad \mbox{if} \enspace a_c = 1 \\
         \end{array}
         \right. \, ,
         $$
      :# }

      where \im{#: \mbox{M}() :#} is the midtones transfer function defined by Equation \eqnref eqn_mtf. Setting \im{l_c = 0} and \im {r_c = 1}, now we have the whole set of parameters to apply an automatic display function to a channel of the image (see Equation \eqnref eqn_display_function).

      For RGB color images, a side effect of this algorithm is the relative alignment of the three histogram peaks, which tends to yield an effective white balance correction. The algorithm can be modified easily to apply a single set of DF parameters to all nominal channels, which preserves the existing color balance. In such case we can calculate, for example:

      \equation[numbered:eqn_linked_df_1] { #:
         $$
         a_0 = a_1 = a_2 = \left\{ \begin{array}{l l}
            0 & \quad \mbox{if} \enspace (M_0 + M_1 + M_2) \le 1.5 \\
            1 & \quad \mbox{if} \enspace (M_0 + M_1 + M_2) > 1.5   \\
         \end{array}
         \right. \, ,
         $$
      :# }

      \equation[numbered:eqn_linked_df_2] { #:
         $$
         s_{RGB} = \frac{s_0 + s_1 + s_2}{3} \, ,
         $$
      :# }

      \equation[numbered:eqn_linked_df_3] { #:
         $$
         h_{RGB} = \frac{h_0 + h_1 + h_2}{3} \, ,
         $$
      :# }

      \equation[numbered:eqn_linked_df_4] { #:
         $$
         m_{RGB} = \frac{m_0 + m_1 + m_2}{3} \, .
         $$
      :# }

      \vs[length:2em]

      \figure {

         \figtag \s { Adaptive display function examples. }

         \s (a) Linear image. A single raw frame acquired with a DSLR camera.

         \s (b) Linear image (a) visualized with separate adaptive display functions computed for each nominal channel. The original color balance of the linear data has been altered.

         \s (c) Linear image (a) visualized with a single adaptive display function computed by Equations \eqnref eqn_linked_df_1, \eqnref eqn_linked_df_2, \eqnref eqn_linked_df_3 and \eqnref eqn_linked_df_4. Note that the original color balance has been preserved.

         \s (d) Linear RGB color image of M74. Composition of three integrated CCD images.

         \s (e) Linear image (d) visualized with separate adaptive display functions computed for each nominal channel.

         \s (f) Linear image (d) visualized with a single adaptive display function.

         \s (g) Histogram of (d), magnified horizontally by a factor of 25.

         In all cases adaptive DFs have been computed with default target background and clipping point parameters, as described in the text. Image of M74 courtesy of Calar Alto Observatory / Vicent Peris.

         \vs[length:2em]
         \group{ \block[float:left] \s a \image[float:right] flower-df-linear.png }
         \vs
         \group{ \block[float:left] \s b \image[float:right] flower-df-unlinked.png }
         \vs
         \group{ \block[float:left] \s c \image[float:right] flower-df-linked.png }
         \vs
         \group{ \block[float:left] \s d \image[float:right] M74-df-linear.png }
         \vs
         \group{ \block[float:left] \s e \image[float:right] M74-df-unlinked.png }
         \vs
         \group{ \block[float:left] \s f \image[float:right] M74-df-linked.png }
         \vs
         \group{ \block[float:left] \s g \group[width:800px,float:right]{ \image[float:left] M74-df-histogram.png } }
      }
   }
}
